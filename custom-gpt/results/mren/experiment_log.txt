+++ Evaluation Results +++ 

++ using sacrebleu ++
{
 "name": "BLEU",
 "score": 36.8,
 "signature": "nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1",
 "verbose_score": "65.8/42.6/30.4/22.0 (BP = 0.996 ratio = 0.996 hyp_len = 7534 ref_len = 7562)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "13a",
 "smooth": "exp",
 "version": "2.4.1"
}
{
 "name": "BLEU",
 "score": 38.8,
 "signature": "nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1",
 "verbose_score": "68.5/44.8/32.0/23.3 (BP = 0.996 ratio = 0.996 hyp_len = 7534 ref_len = 7562)",
 "nrefs": "1",
 "case": "lc",
 "eff": "no",
 "tok": "13a",
 "smooth": "exp",
 "version": "2.4.1"
}
{
 "name": "TER",
 "score": 53.9,
 "signature": "nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1",
 "nrefs": "1",
 "case": "lc",
 "tok": "tercom",
 "norm": "no",
 "punct": "yes",
 "asian": "no",
 "version": "2.4.1"
}
{
 "name": "chrF1",
 "score": 61.6,
 "signature": "nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1",
 "nrefs": "1",
 "case": "mixed",
 "eff": "yes",
 "nc": "6",
 "nw": "0",
 "space": "no",
 "version": "2.4.1"
}
{
 "name": "chrF3",
 "score": 62.6,
 "signature": "nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1",
 "nrefs": "1",
 "case": "mixed",
 "eff": "yes",
 "nc": "6",
 "nw": "0",
 "space": "no",
 "version": "2.4.1"
}
+++ Evaluation Results on GPT4 baseline with MREN +++ 

++ using sacrebleu ++
{
 "name": "BLEU",
 "score": 37.1,
 "signature": "nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1",
 "verbose_score": "65.2/42.6/30.6/22.3 (BP = 1.000 ratio = 1.003 hyp_len = 7585 ref_len = 7562)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "13a",
 "smooth": "exp",
 "version": "2.4.1"
}
{
 "name": "BLEU",
 "score": 38.6,
 "signature": "nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1",
 "verbose_score": "67.3/44.3/31.9/23.4 (BP = 1.000 ratio = 1.003 hyp_len = 7585 ref_len = 7562)",
 "nrefs": "1",
 "case": "lc",
 "eff": "no",
 "tok": "13a",
 "smooth": "exp",
 "version": "2.4.1"
}
{
 "name": "TER",
 "score": 54.6,
 "signature": "nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1",
 "nrefs": "1",
 "case": "lc",
 "tok": "tercom",
 "norm": "no",
 "punct": "yes",
 "asian": "no",
 "version": "2.4.1"
}
{
 "name": "chrF1",
 "score": 60.7,
 "signature": "nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1",
 "nrefs": "1",
 "case": "mixed",
 "eff": "yes",
 "nc": "6",
 "nw": "0",
 "space": "no",
 "version": "2.4.1"
}
{
 "name": "chrF3",
 "score": 61.7,
 "signature": "nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1",
 "nrefs": "1",
 "case": "mixed",
 "eff": "yes",
 "nc": "6",
 "nw": "0",
 "space": "no",
 "version": "2.4.1"
}
