{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGCNJwRD1QGPBsgZKR071a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"IM0C7al8AUdu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711924815258,"user_tz":-60,"elapsed":21964,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"1ade6b4e-ee16-4d4f-fada-9d544d98ed37"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYt4I6e0N8w0","executionInfo":{"status":"ok","timestamp":1711924832037,"user_tz":-60,"elapsed":15056,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"58a9d812-65c4-4b38-e118-1e552c4da6e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sacrebleu[ja]\n","  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/106.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu[ja])\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]) (1.25.2)\n","Collecting colorama (from sacrebleu[ja])\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]) (4.9.4)\n","Collecting mecab-python3<=1.0.6,>=1.0.5 (from sacrebleu[ja])\n","  Downloading mecab_python3-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.6/581.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipadic<2.0,>=1.0 (from sacrebleu[ja])\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=a67500ac3977e350dcf4bb28bdd1c7eee3a8387e0f36caa1a4651dd0e3a398cc\n","  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n","Successfully built ipadic\n","Installing collected packages: mecab-python3, ipadic, portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 ipadic-1.0.0 mecab-python3-1.0.6 portalocker-2.8.2 sacrebleu-2.4.1\n"]}],"source":["!pip3 install sacrebleu[ja]"]},{"cell_type":"code","source":["%cd drive/MyDrive/exp/crisismt/results/enga"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JH1g6tE_Ofw1","executionInfo":{"status":"ok","timestamp":1710777212366,"user_tz":0,"elapsed":516,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"e66f93be-04df-4094-a266-04e93b3b92dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/results/enga\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results +++ \\n\" | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m bleu -lc --force \\\n","  | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 1 --force \\\n","  | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 3 --force \\\n","  | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtI7TQVEOTYS","executionInfo":{"status":"ok","timestamp":1710777264076,"user_tz":0,"elapsed":4180,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"3923c7d7-55de-4db1-b0d2-84baeb8a44df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 32.3,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"64.5/40.4/27.6/19.7 (BP = 0.936 ratio = 0.938 hyp_len = 6166 ref_len = 6577)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 32.8,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"65.4/40.9/28.1/20.1 (BP = 0.936 ratio = 0.938 hyp_len = 6166 ref_len = 6577)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 55.3,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 60.6,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 59.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/results/gaen"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCTgpEAXOoUp","executionInfo":{"status":"ok","timestamp":1710777842923,"user_tz":0,"elapsed":238,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"332084c2-0473-4018-d7b2-a73b4f4877fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/results/gaen\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results +++ \\n\" | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m bleu -lc --force \\\n","| tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 1 --force \\\n","  | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 3 --force \\\n","  | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqBESxA1Or51","executionInfo":{"status":"ok","timestamp":1710777850178,"user_tz":0,"elapsed":3691,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"061278e6-fc9c-4e45-8932-3e1d13fbb95b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 52.1,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"75.5/57.7/45.8/37.0 (BP = 1.000 ratio = 1.049 hyp_len = 3993 ref_len = 3807)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 53.2,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"76.9/58.9/46.8/37.7 (BP = 1.000 ratio = 1.049 hyp_len = 3993 ref_len = 3807)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 37.0,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 72.8,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 74.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/results/enmr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8L7bUo_lOp0T","executionInfo":{"status":"ok","timestamp":1710777360425,"user_tz":0,"elapsed":199,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"e6618e6b-81dc-43c3-a7fa-128750b76736"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/results/enmr\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results +++ \\n\" | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m bleu -lc --force \\\n","  | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 1 --force \\\n","  | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 3 --force \\\n","  | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0uI1rrlQyfl","executionInfo":{"status":"ok","timestamp":1710777370340,"user_tz":0,"elapsed":4937,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"f4bd94c6-291c-4496-a09d-dde1eed32562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 19.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"52.1/25.9/14.2/8.5 (BP = 0.946 ratio = 0.948 hyp_len = 6609 ref_len = 6975)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 19.0,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"52.1/25.9/14.2/8.5 (BP = 0.946 ratio = 0.948 hyp_len = 6609 ref_len = 6975)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 67.8,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 54.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 52.8,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/results/mren"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710839276014,"user_tz":0,"elapsed":378,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"e2dfddf3-0089-4a30-c43d-ccb9e4741211","id":"4QaOEi-o81x6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/results/mren\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results +++ \\n\" | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m bleu -lc --force \\\n","  | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < pred.txt -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 1 --force \\\n","  | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < pred.txt -m chrf --chrf-beta 3 --force \\\n","  | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710839281740,"user_tz":0,"elapsed":5729,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"421bd651-2483-4fef-a44d-c0588cc9c147","id":"YfoxCHwX9Cwm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 36.8,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"65.8/42.6/30.4/22.0 (BP = 0.996 ratio = 0.996 hyp_len = 7534 ref_len = 7562)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 38.8,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"68.5/44.8/32.0/23.3 (BP = 0.996 ratio = 0.996 hyp_len = 7534 ref_len = 7562)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 53.9,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 61.6,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 62.6,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/custom-gpt/results/enga"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711924884440,"user_tz":-60,"elapsed":266,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"b063da85-41f1-4374-c373-40cda9cecc3e","id":"oqmpp15pl1iB"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/custom-gpt/results/enga\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results on GPT4 baseline with ENGA +++ \\n\" \\\n","  | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < irish-target-test-GPT4-baseline.txt \\\n","  -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < irish-target-test-GPT4-baseline.txt \\\n","  -m bleu -lc --force | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < irish-target-test-GPT4-baseline.txt \\\n","  -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < irish-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 1 --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < irish-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 3 --force | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711924929609,"user_tz":-60,"elapsed":5596,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"8dc2a3b5-781b-41a5-9b36-0741c1c5c519","id":"dpju0sVzl5yu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results on GPT4 baseline with ENGA +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 30.8,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"63.9/38.7/25.9/18.1 (BP = 0.937 ratio = 0.939 hyp_len = 6177 ref_len = 6577)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 31.1,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"64.7/39.1/26.2/18.4 (BP = 0.937 ratio = 0.939 hyp_len = 6177 ref_len = 6577)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 56.4,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 59.6,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 58.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/custom-gpt/results/gaen"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1cvbWrRpeVx","executionInfo":{"status":"ok","timestamp":1711924952069,"user_tz":-60,"elapsed":239,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"0756588e-91c3-4ada-a047-c3b89b3a6a33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/custom-gpt/results/gaen\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results on GPT4 baseline with GAEN +++ \\n\" \\\n","  | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m bleu -lc --force | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 1 --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 3 --force | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ToAM52Gpgkn","executionInfo":{"status":"ok","timestamp":1711924977267,"user_tz":-60,"elapsed":4445,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"b6e286d8-c378-4134-f375-05efc706e8ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results on GPT4 baseline with GAEN +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 53.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"76.1/58.4/46.7/37.9 (BP = 1.000 ratio = 1.045 hyp_len = 3980 ref_len = 3807)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 53.9,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"77.6/59.6/47.5/38.5 (BP = 1.000 ratio = 1.045 hyp_len = 3980 ref_len = 3807)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 36.5,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 73.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 75.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/custom-gpt/results/enmr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uO9Ux6rp9s9","executionInfo":{"status":"ok","timestamp":1711924992214,"user_tz":-60,"elapsed":249,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"19377f89-eb5a-48ba-b83e-14b02e13ae1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/custom-gpt/results/enmr\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results on GPT4 baseline with ENMR +++ \\n\" \\\n","  | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < marathi-target-test-GPT4-baseline.txt \\\n","  -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < marathi-target-test-GPT4-baseline.txt \\\n","  -m bleu -lc --force | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < marathi-target-test-GPT4-baseline.txt \\\n","  -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < marathi-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 1 --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < marathi-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 3 --force | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uxm-9D1Hp_DA","executionInfo":{"status":"ok","timestamp":1711925017349,"user_tz":-60,"elapsed":4734,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"435ed7ff-a595-4ea7-d81d-111de72625c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results on GPT4 baseline with ENMR +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 18.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"51.7/25.3/13.6/8.1 (BP = 0.948 ratio = 0.949 hyp_len = 6622 ref_len = 6975)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 18.5,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"51.7/25.3/13.6/8.1 (BP = 0.948 ratio = 0.949 hyp_len = 6622 ref_len = 6975)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 68.9,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 54.3,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 52.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/exp/crisismt/custom-gpt/results/mren"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfTkwSJuqQ01","executionInfo":{"status":"ok","timestamp":1711925031740,"user_tz":-60,"elapsed":234,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"d49a5847-cb3a-4908-83b7-24e854ead776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/exp/crisismt/custom-gpt/results/mren\n"]}]},{"cell_type":"code","source":["!echo -e \"+++ Evaluation Results on GPT4 baseline with MREN +++ \\n\" \\\n","  | tee -a experiment_log.txt\n","!echo \"++ using sacrebleu ++\" | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m bleu --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m bleu -lc --force | tee -a experiment_log.txt\n","\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m ter --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 1 --force | tee -a experiment_log.txt\n","!sacrebleu tgt-test.txt < english-target-test-GPT4-baseline.txt \\\n","  -m chrf --chrf-beta 3 --force | tee -a experiment_log.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5nG9TQHqSGN","executionInfo":{"status":"ok","timestamp":1711925064378,"user_tz":-60,"elapsed":6377,"user":{"displayName":"Seamus Lankford","userId":"06302770712845215478"}},"outputId":"b411267c-2129-4756-f852-48e5e63a010b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+++ Evaluation Results on GPT4 baseline with MREN +++ \n","\n","++ using sacrebleu ++\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 37.1,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"65.2/42.6/30.6/22.3 (BP = 1.000 ratio = 1.003 hyp_len = 7585 ref_len = 7562)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 38.6,\n"," \"signature\": \"nrefs:1|case:lc|eff:no|tok:13a|smooth:exp|version:2.4.1\",\n"," \"verbose_score\": \"67.3/44.3/31.9/23.4 (BP = 1.000 ratio = 1.003 hyp_len = 7585 ref_len = 7562)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"TER\",\n"," \"score\": 54.6,\n"," \"signature\": \"nrefs:1|case:lc|tok:tercom|norm:no|punct:yes|asian:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"lc\",\n"," \"tok\": \"tercom\",\n"," \"norm\": \"no\",\n"," \"punct\": \"yes\",\n"," \"asian\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF1\",\n"," \"score\": 60.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n","{\n"," \"name\": \"chrF3\",\n"," \"score\": 61.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:0|space:no|version:2.4.1\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"yes\",\n"," \"nc\": \"6\",\n"," \"nw\": \"0\",\n"," \"space\": \"no\",\n"," \"version\": \"2.4.1\"\n","}\n"]}]}]}