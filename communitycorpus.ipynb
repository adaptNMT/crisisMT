{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Community Corpus Development**\n",
        "\n",
        "\n",
        "A Colab tool which helps with the development of community-driven corpora using LLM engines. It's the first iteration of the tool and may be developed further. Improvements could include support for LLMs other than ChatGPT and CoPilot."
      ],
      "metadata": {
        "id": "2Oo2-clgpiiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYIzlH9eV--0"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install openai==0.28\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please enter your API keys for Gen AI engines**"
      ],
      "metadata": {
        "id": "cv5J8BbBo0Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### API Keys for Gen AI engines:\n",
        "\n",
        "#@markdown ### Which GenAI engines are you using:\n",
        "chatGPT = True #@param {type:\"boolean\"}\n",
        "copilot = False #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "lsGiYGcAozMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if chatGPT == True:\n",
        "  chatGPTapi = \"Enter your API key here\" #@param {type:\"string\"}\n",
        "\n",
        "if copilot == True:\n",
        "  copilotapi = \"Enter your API key here\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "IBLvU_76qup9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gUC3E6zUtvj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set your LLM API key\n",
        "# chatGPT being used by default but change if other custom GPT LLM being used\n",
        "openai.api_key = chatGPTapi\n",
        "\n",
        "def log_conversation(log_file, user_input, response):\n",
        "    timestamp = datetime.now().isoformat()\n",
        "    log_entry = {\n",
        "        'timestamp': timestamp,\n",
        "        'user_input': user_input,\n",
        "        'response': response\n",
        "    }\n",
        "    with open('/content/conversation_log.txt', 'a') as f:\n",
        "        f.write(json.dumps(log_entry) + '\\n')\n",
        "\n",
        "def chat_with_gpt(enginetype,custom_source,custom_destination,prompt,log_file='/content/conversation_log.txt'):\n",
        "\n",
        "# Set your LLM Engine\n",
        "# gpt-3.5-turbo-instruct being used by default but change if other LLM being used\n",
        "\n",
        "   if enginetype ==  \"gpt-3.5-turbo-instruct\":\n",
        "      response = openai.Completion.create(\n",
        "          engine=enginetype,\n",
        "          prompt=prompt,\n",
        "          max_tokens=250\n",
        "      )\n",
        "      response_text = response['choices'][0]['text'].strip()\n",
        "      log_conversation(log_file, prompt, response_text)\n",
        "\n",
        "   else:\n",
        "        log_conversation(log_file, custom_source,custom_destination)\n",
        "        response_text = 'GPT not used - custom translation stored'\n",
        "\n",
        "   return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUTsTtBPMFSx"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the dropdown options\n",
        "# gpt-3.5-turbo-instruct being used by default but change if other LLM being used\n",
        "dropdown_options = [\"gpt-3.5-turbo-instruct\", \"Custom Entry\"]\n",
        "\n",
        "# Define your input component using the dropdown\n",
        "dropdown_input = gr.Dropdown(choices=dropdown_options, label=\"Choose an option\")\n",
        "\n",
        "# Define the interface\n",
        "iface = gr.Interface(\n",
        "    fn=chat_with_gpt,\n",
        "    inputs=[dropdown_input,\"text\",\"text\", \"text\",\"text\"],\n",
        "    outputs=\"text\",\n",
        "    title=\"Community Driven Corpus Creation\",\n",
        "    description=\"Web app which enables rapid community corpus development\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "iface.launch(debug=True)\n",
        "\n",
        "# The gradio app may also be deployed on HuggingFace\n",
        "# !gradio deploy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}